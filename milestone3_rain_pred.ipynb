{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross-Validation and Hyperparameter Tuning using GridSearchCV\n",
    "The Notebook offers an example solution for the third milestone of the Rain Prediction second project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "We are using the [Rainfall prediction dataset from Kaggle](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package) which cotains daily weather observations from numerous Austrailian weather stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing libraries\n",
    "import numpy as np  #for algebraic operations on arrays\n",
    "import pandas as pd  #for data exploration and manipulation\n",
    "\n",
    "\n",
    "##plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading, Cleaning and Fitting the Dataset\n",
    "Refer to milestone 1 if you have forgotten why were doing the following steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data\n",
    "X_train=pd.read_csv('data/X_train.csv')\n",
    "X_test=pd.read_csv('data/X_test.csv')\n",
    "y_train=pd.read_csv('data/y_train.csv')\n",
    "y_test=pd.read_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the data\n",
    "X_train=X_train.iloc[:,1:]\n",
    "X_test=X_test.iloc[:,1:]\n",
    "y_train=y_train[\"RainTomorrow\"]\n",
    "y_test=y_test[\"RainTomorrow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Instantiate the model class\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "#Train the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation and Hyperparameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to use all the available data to assess the quality of models and get more reliable validation results. We can simply perform validation multiple times.\n",
    "\n",
    "First, we split the training dataset into a certain number of parts (say, three). Then we train a model on two parts and validate on the remaining one. We repeat this process three times, and at the end get three different scores. This is exactly the idea behind K-fold cross-validation.\n",
    "\n",
    "![Image](https://drek4537l1klr.cloudfront.net/grigorev/v-6/Figures/04_38.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, when working with machine learning models, we need to split our model into 3 sets (not 2, like done upto now), the training set, the validation set and the test set. The reason is because if we have just one single test set, we end up tuning our hyperparameters based on the metrics of the test set, and hence in a sense, our model is adapted to our test set lessening the reason for the test set in the first place - to test our model on data it has never seen. But because we are now splitting it into three parts, the training set may further get reduced, worsening the model. The solution is to use K-Fold Cross Validation on the test set, and reserve a part of the dataset for the final testing at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.39679313, 1.43390441, 1.17910504, 1.35417247, 1.51000261]),\n",
       " 'score_time': array([0.11235046, 0.10819411, 0.10589981, 0.10441613, 0.11729145]),\n",
       " 'test_accuracy': array([0.84668806, 0.8481825 , 0.84734737, 0.84914949, 0.84395604]),\n",
       " 'test_roc_auc': array([0.86967067, 0.87256227, 0.86974046, 0.86918609, 0.86681804])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the required \n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "#We are using KFold to split the dataset, but alternatively we could just specify integer values for cv\n",
    "kf = KFold(5,shuffle=True,random_state=0)\n",
    "cv_scores = cross_validate(logreg,X_train,y_train,cv=kf,scoring=['accuracy','roc_auc'])\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score for the data: 0.8471\n",
      "Mean AUC score for the data: 0.8696\n"
     ]
    }
   ],
   "source": [
    "#Print the mean accuracy score and AUC score for all the splits\n",
    "\n",
    "print('Mean accuracy score for the data: {0:0.4f}'.format(cv_scores['test_accuracy'].mean()))\n",
    "print('Mean AUC score for the data: {0:0.4f}'.format(cv_scores['test_roc_auc'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this concept of Cross Validation to use **GridSearchCV** to find the best parameters for our Logistic Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n",
      "[CV] C=0.001, solver=liblinear .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ C=0.001, solver=liblinear, total=   0.4s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ C=0.001, solver=liblinear, total=   0.4s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV] ........................ C=0.001, solver=liblinear, total=   0.4s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] ............................ C=0.001, solver=lbfgs, total=   0.5s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] ............................ C=0.001, solver=lbfgs, total=   0.5s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] ............................ C=0.001, solver=lbfgs, total=   0.6s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ............................. C=0.001, solver=saga, total=   1.8s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ............................. C=0.001, solver=saga, total=   1.9s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ............................. C=0.001, solver=saga, total=   2.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV] ......................... C=0.01, solver=liblinear, total=   0.6s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV] ......................... C=0.01, solver=liblinear, total=   0.5s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV] ......................... C=0.01, solver=liblinear, total=   0.6s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ............................. C=0.01, solver=lbfgs, total=   0.9s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ............................. C=0.01, solver=lbfgs, total=   1.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ............................. C=0.01, solver=lbfgs, total=   1.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .............................. C=0.01, solver=saga, total=   1.9s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .............................. C=0.01, solver=saga, total=   1.9s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .............................. C=0.01, solver=saga, total=   2.1s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV] .......................... C=0.1, solver=liblinear, total=   0.7s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV] .......................... C=0.1, solver=liblinear, total=   0.7s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV] .......................... C=0.1, solver=liblinear, total=   0.7s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .............................. C=0.1, solver=lbfgs, total=   1.4s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .............................. C=0.1, solver=lbfgs, total=   1.4s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .............................. C=0.1, solver=lbfgs, total=   1.4s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ............................... C=0.1, solver=saga, total=   1.7s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ............................... C=0.1, solver=saga, total=   1.7s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ............................... C=0.1, solver=saga, total=   1.7s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] ............................ C=1, solver=liblinear, total=   0.9s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] ............................ C=1, solver=liblinear, total=   1.1s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] ............................ C=1, solver=liblinear, total=   0.9s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ................................ C=1, solver=lbfgs, total=   1.3s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ................................ C=1, solver=lbfgs, total=   1.4s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ................................ C=1, solver=lbfgs, total=   1.3s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ................................. C=1, solver=saga, total=   7.5s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ................................. C=1, solver=saga, total=   7.7s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ................................. C=1, solver=saga, total=   7.5s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] ........................... C=10, solver=liblinear, total=   1.0s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] ........................... C=10, solver=liblinear, total=   0.9s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] ........................... C=10, solver=liblinear, total=   1.0s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ............................... C=10, solver=lbfgs, total=   1.5s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ............................... C=10, solver=lbfgs, total=   1.3s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ............................... C=10, solver=lbfgs, total=   1.3s\n",
      "[CV] C=10, solver=saga ...............................................\n",
      "[CV] ................................ C=10, solver=saga, total=   9.2s\n",
      "[CV] C=10, solver=saga ...............................................\n",
      "[CV] ................................ C=10, solver=saga, total=   9.3s\n",
      "[CV] C=10, solver=saga ...............................................\n",
      "[CV] ................................ C=10, solver=saga, total=   9.2s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV] .......................... C=100, solver=liblinear, total=   1.0s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV] .......................... C=100, solver=liblinear, total=   1.1s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV] .......................... C=100, solver=liblinear, total=   1.2s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .............................. C=100, solver=lbfgs, total=   1.4s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .............................. C=100, solver=lbfgs, total=   1.4s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .............................. C=100, solver=lbfgs, total=   1.4s\n",
      "[CV] C=100, solver=saga ..............................................\n",
      "[CV] ............................... C=100, solver=saga, total=   2.6s\n",
      "[CV] C=100, solver=saga ..............................................\n",
      "[CV] ............................... C=100, solver=saga, total=   2.6s\n",
      "[CV] C=100, solver=saga ..............................................\n",
      "[CV] ............................... C=100, solver=saga, total=   2.5s\n",
      "[CV] C=1000, solver=liblinear ........................................\n",
      "[CV] ......................... C=1000, solver=liblinear, total=   1.0s\n",
      "[CV] C=1000, solver=liblinear ........................................\n",
      "[CV] ......................... C=1000, solver=liblinear, total=   1.1s\n",
      "[CV] C=1000, solver=liblinear ........................................\n",
      "[CV] ......................... C=1000, solver=liblinear, total=   1.0s\n",
      "[CV] C=1000, solver=lbfgs ............................................\n",
      "[CV] ............................. C=1000, solver=lbfgs, total=   1.4s\n",
      "[CV] C=1000, solver=lbfgs ............................................\n",
      "[CV] ............................. C=1000, solver=lbfgs, total=   1.3s\n",
      "[CV] C=1000, solver=lbfgs ............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................. C=1000, solver=lbfgs, total=   1.4s\n",
      "[CV] C=1000, solver=saga .............................................\n",
      "[CV] .............................. C=1000, solver=saga, total=   2.5s\n",
      "[CV] C=1000, solver=saga .............................................\n",
      "[CV] .............................. C=1000, solver=saga, total=   2.5s\n",
      "[CV] C=1000, solver=saga .............................................\n",
      "[CV] .............................. C=1000, solver=saga, total=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'solver': ['liblinear', 'lbfgs', 'saga']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#We are creating a dictionary of all the permutations of parameters we wish to try out for the model\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'solver' : ['liblinear','lbfgs','saga']}\n",
    "#In the above grid, we will effectively be trying out 7*3 = 21 models\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(),param_grid,cv=3,verbose=2)\n",
    "\n",
    "#Fit the classifier to obtain the best model for our data. This may take some time!\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us check out the best parameters for our model\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for test data: 0.8489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#We now use the classifer with the best model to predict the labels for our test set and check its accuracy\n",
    "y_pred_test_grid = clf.predict(X_test)\n",
    "print('Accuracy score for test data: {0:0.4f}'.format(accuracy_score(y_test, y_pred_test_grid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.86      0.88     22137\n",
      "         Yes       0.59      0.70      0.64      6302\n",
      "\n",
      "    accuracy                           0.83     28439\n",
      "   macro avg       0.75      0.78      0.76     28439\n",
      "weighted avg       0.84      0.83      0.83     28439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#Let us now check the confusion matrix and classification report for this model and compare it to our initial one\n",
    "#Set the threshold value manually\n",
    "threshold = 0.3\n",
    "\n",
    "BoolArray=clf.predict_proba(X_test)[:,1]>=threshold\n",
    "predictions_grid=np.array(['Yes' if val==True else 'No' for val in BoolArray])\n",
    "\n",
    "#Plotting the Confusion Matrix\n",
    "cm = confusion_matrix(y_test,predictions_grid)\n",
    "cmdf=pd.DataFrame(cm,index=[\"No\",\"Yes\"],columns=[\"No\",\"Yes\"])\n",
    "fig,ax=plt.subplots(1,1)\n",
    "sns.heatmap(cmdf,annot=True,fmt='d',ax=ax)\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "#Printing the Classification Report\n",
    "print(classification_report(y_test,predictions_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model after GridSearchCV is very comparable to the initial model we had. Accuracy is idenitical upto 4 decimal places but f1 score for \"Yes\" has increased while f1 score for \"No\" has decreased. Let's go ahead with the final model with a threshold value of 0.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogReg_Model.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the model\n",
    "\n",
    "lr = clf.best_estimator_\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "import joblib #Install the library if you do not have it or import it from sklearn.externals\n",
    "joblib.dump(lr,'LogReg_Model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
